{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "\n",
    "import collections\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Dense, LSTM, Dropout, Input, Embedding\n",
    "\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3.0\n",
      "2.0.8\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Description</th>\n",
       "      <th>Browser_Used</th>\n",
       "      <th>Device_Used</th>\n",
       "      <th>Is_Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id10326</td>\n",
       "      <td>The room was kind of clean but had a VERY stro...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id10327</td>\n",
       "      <td>I stayed at the Crown Plaza April -- - April -...</td>\n",
       "      <td>Internet Explorer</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id10328</td>\n",
       "      <td>I booked this hotel through Hotwire at the low...</td>\n",
       "      <td>Mozilla</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id10329</td>\n",
       "      <td>Stayed here with husband and sons on the way t...</td>\n",
       "      <td>InternetExplorer</td>\n",
       "      <td>Desktop</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id10330</td>\n",
       "      <td>My girlfriends and I stayed here to celebrate ...</td>\n",
       "      <td>Edge</td>\n",
       "      <td>Tablet</td>\n",
       "      <td>not happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID                                        Description  \\\n",
       "0  id10326  The room was kind of clean but had a VERY stro...   \n",
       "1  id10327  I stayed at the Crown Plaza April -- - April -...   \n",
       "2  id10328  I booked this hotel through Hotwire at the low...   \n",
       "3  id10329  Stayed here with husband and sons on the way t...   \n",
       "4  id10330  My girlfriends and I stayed here to celebrate ...   \n",
       "\n",
       "        Browser_Used Device_Used Is_Response  \n",
       "0               Edge      Mobile   not happy  \n",
       "1  Internet Explorer      Mobile   not happy  \n",
       "2            Mozilla      Tablet   not happy  \n",
       "3   InternetExplorer     Desktop       happy  \n",
       "4               Edge      Tablet   not happy  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load ascii text and covert to lowercase\n",
    "filename = \"hotel-reviews.csv\"\n",
    "\n",
    "reviews_df = pd.read_csv(filename)\n",
    "\n",
    "reviews_df.head()\n",
    "\n",
    "#raw_text = open(filename).read()\n",
    "#raw_text = raw_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reviews = np.array(reviews_df['Description'])\n",
    "devices = np.array(reviews_df['Device_Used'])\n",
    "responses = np.array(reviews_df['Is_Response'])\n",
    "\n",
    "\n",
    "for i, review in enumerate(reviews):\n",
    "    review = review.lower()\n",
    "    review = review.replace('\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"', '\"')\n",
    "    reviews[i] = review\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33216138"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_text = \" \".join(reviews).lower()\n",
    "len(reviews_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create mapping of unique chars to integers\n",
    "\n",
    "voc_cnt = collections.Counter(reviews_text.split())\n",
    "vocab = sorted(voc_cnt, key=voc_cnt.get, reverse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "highFrequencyWords = [x[0] for x in voc_cnt.items() if x[1] > 10]\n",
    "len(highFrequencyWords)\n",
    "highFrequencyWords.insert(0,'<EOS>')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(vocab)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<EOS>\n",
      "Total Vocab:  15634\n",
      "words 6125855\n",
      "total number of unique words 15634\n",
      "total highFrequencyWords: 15634\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "words = sorted(list(set(highFrequencyWords)))\n",
    "\n",
    "total_words = len(reviews_text.split())\n",
    "\n",
    "# Lookup tables\n",
    "word_to_int = dict((c, i) for i, c in enumerate(highFrequencyWords))\n",
    "int_to_word = dict((i, c) for i, c in enumerate(highFrequencyWords)) \n",
    "\n",
    "# summarize the loaded data\n",
    "print(word_to_int['<EOS>'])\n",
    "print(int_to_word[0])\n",
    "n_vocab_words = len(words)\n",
    "\n",
    "print(\"Total Vocab: \", n_vocab_words)\n",
    "print(\"words\",total_words)\n",
    "print(\"total number of unique words\", n_vocab_words)\n",
    "print('total highFrequencyWords:', len(highFrequencyWords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "304\n",
      "15634\n"
     ]
    }
   ],
   "source": [
    "print(int_to_word[1])\n",
    "print(word_to_int['since'])\n",
    "print(len(word_to_int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 147, 69, 431, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_review_to_word_id(raw_review):\n",
    "    review_word_ids = []\n",
    "    raw_review = raw_review.lower()\n",
    "    for word in raw_review.split():\n",
    "        if word in word_to_int:\n",
    "            word_id = word_to_int[word]\n",
    "            review_word_ids.append(word_id)\n",
    "        else:\n",
    "            review_word_ids.append(0)\n",
    "    return review_word_ids\n",
    "\n",
    "\n",
    "convert_review_to_word_id(\"the hotel is good hahaha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 142, 91, 242, 33, 243, 64, 1, 244, 76, 245, 246, 247, 153, 225, 248, 1, 249, 180, 250, 251, 18, 9, 2, 64, 1, 252, 253, 254, 252, 255, 18, 1, 212, 256, 153, 8, 9, 65, 257, 91, 9, 258, 259, 5, 1, 260, 1, 261, 33, 262, 1, 263, 0, 153, 264, 2, 265, 18, 266, 211, 153, 100, 267, 1, 268, 256, 2, 265, 269, 107, 270, 271, 272, 53, 59, 9, 268, 273, 76, 274, 275, 211, 267, 1, 276, 277, 0, 278, 83, 107, 0, 271]\n",
      "wonderful staff, great location, but it was definately the price was high for a standard hotel. the free breakfast was great, actually pretty good <EOS> for a free buffet. this hotel is in the heart of it all, walking distance to everything. - things, please <EOS> coffee was bad and the white ginger line of <EOS> smells horrible!\n",
      "[ 0.  1.]\n"
     ]
    }
   ],
   "source": [
    "reviews_int = []\n",
    "sentiments_int = []\n",
    "\n",
    "\n",
    "for review in reviews:\n",
    "    review_ids = []\n",
    "    reviews_int.append(convert_review_to_word_id(review))\n",
    "\n",
    "reviews_int = np.array(reviews_int)\n",
    "\n",
    "for sentiment in responses:\n",
    "    if sentiment == \"happy\":\n",
    "        sentiments_int.append(1)\n",
    "    else:\n",
    "        sentiments_int.append(0)\n",
    "\n",
    "sentiments_int = np_utils.to_categorical(sentiments_int)\n",
    "        \n",
    "print(reviews_int[3])\n",
    "print(\" \".join([int_to_word[word_id] for word_id in reviews_int[9]]))\n",
    "print(sentiments_int[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(31145,)\n",
      "(7787,)\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 5, 13, 14, 15, 16, 7, 17, 18, 9, 19, 20, 21, 22, 23, 24, 0, 25, 26, 27, 28, 21, 1, 29, 3, 30, 31, 3, 32, 33, 34, 35, 36, 37, 38]\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12  5 13 14 15 16  7 17 18  9 19 20 21 22\n",
      " 23 24  0 25 26 27 28 21  1 29  3 30 31  3 32 33 34 35 36 37 38  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      "(31145, 120)\n",
      "(31145, 2)\n",
      "(7787, 120)\n"
     ]
    }
   ],
   "source": [
    "#reviews_int = np.reshape(reviews_int, (len(reviews_int), 80, 1))\n",
    "trainLen = int(len(reviews_int)*0.8)\n",
    "\n",
    "train_dataX = reviews_int[:trainLen]\n",
    "train_dataY = sentiments_int[:trainLen]\n",
    "test_dataX = reviews_int[trainLen:]\n",
    "test_dataY = sentiments_int[trainLen:]\n",
    "\n",
    "print(train_dataX.shape)\n",
    "print(test_dataX.shape)\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "print(train_dataX[0])\n",
    "\n",
    "train_dataX = sequence.pad_sequences(train_dataX, maxlen=120, padding='post')\n",
    "test_dataX = sequence.pad_sequences(test_dataX, maxlen=120, padding='post')\n",
    "\n",
    "train_dataY = np.array(train_dataY)\n",
    "test_dataY = np.array(test_dataY)\n",
    "\n",
    "print(train_dataX[0])\n",
    "\n",
    "print(train_dataX.shape)\n",
    "print(train_dataY.shape)\n",
    "print(test_dataX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataY[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 120)\n",
      "(?, 120, 128)\n"
     ]
    }
   ],
   "source": [
    "inp = Input(shape=(train_dataX.shape[1], ))\n",
    "print(inp.shape)\n",
    "x = Embedding(n_vocab_words, 128)(inp)\n",
    "print(x.shape)\n",
    "#x = Embedding(n_vocab_words, 256, input_length=80)(inp)\n",
    "x = LSTM(128, return_sequences=True)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = LSTM(256)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "#x = LSTM(256)(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "output = Dense(2, activation ='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 120, 128)          2001152   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 120, 128)          131584    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 120, 128)          0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               394240    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 2,527,490\n",
      "Trainable params: 2,527,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs = inp, outputs=output )\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the checkpoint callback\n",
    "filepath=\"checkpoints/hotel-sentiments-weights-{epoch:02d}-{loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "reduce_LR = ReduceLROnPlateau(monitor='loss',factor = 0.9, patience=3,cooldown=2, min_lr = 0.00001)\n",
    "callbacks_list = [checkpoint,reduce_LR]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('checkpoints/hotel-sentiments-weights-00-0.4795.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "31104/31145 [============================>.] - ETA: 0s - loss: 0.5810 - acc: 0.7144Epoch 00000: loss improved from inf to 0.58084, saving model to checkpoints/hotel-sentiments-weights-00-0.5808.hdf5\n",
      "31145/31145 [==============================] - 481s - loss: 0.5808 - acc: 0.7145   \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1f92312b400>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_dataX, train_dataY, epochs=1, batch_size=64, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model/hotel-sentiments-model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model/hotel-sentiments-model.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1  3631    69     9  2384  7171 13926  5130   193     1    83    33\n",
      "  1745    53  1979   101    76   389    18   457     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n",
      "[ 0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print((test_dataX[7786]))\n",
    "print((test_dataY[7786]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7787\n",
      "7785/7785 [==============================] - 33s    \n",
      "score: 0.347085652335\n",
      "acc: 0.863455362893\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataX))\n",
    "score, acc = model.evaluate(test_dataX[:7785], test_dataY[:7785])\n",
    "print('score:', score)\n",
    "print('acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7787\n",
      "7787/7787 [==============================] - 41s    \n",
      "score: 0.411762732412\n",
      "acc: 0.834275073833\n"
     ]
    }
   ],
   "source": [
    "print(len(test_dataX))\n",
    "score, acc = model.evaluate(test_dataX, test_dataY)\n",
    "print('score:', score)\n",
    "print('acc:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictionResult(prediction):\n",
    "    if np.argmax(prediction) == 0:\n",
    "        return \"Negative Review\"\n",
    "    else:\n",
    "        return \"Positive Review\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out the prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 1: [[ 0.77551299  0.22635365]] Negative Review\n",
      "Review 2: [[ 0.06128515  0.94087225]] Positive Review\n",
      "Review 3: [[ 0.77552378  0.22634478]] Negative Review\n"
     ]
    }
   ],
   "source": [
    "def predict_review(raw_review):\n",
    "    review_word_ids = convert_review_to_word_id(raw_review)\n",
    "    #print(review_word_ids)\n",
    "    review_word_ids = np.reshape(review_word_ids, (1, len(review_word_ids)))\n",
    "    #print(review_word_ids)\n",
    "    review_word_ids = sequence.pad_sequences(review_word_ids, maxlen=120, padding='post')\n",
    "    #print(review_word_ids)\n",
    "    review_word_ids = np.array(review_word_ids)\n",
    "    review_word_ids = np.reshape(review_word_ids, (1, 120))\n",
    "    return model.predict(review_word_ids)\n",
    "\n",
    "predict_review1 = predict_review(\"this hotel is bad.\")\n",
    "predict_review2 = predict_review(\"this hotel is good.\")\n",
    "predict_review3 = predict_review(\"The hotel staff specially front desk are not cooperative. Their behaviour is very bad. Room are not properly clean and uun hhealthy specially bathroom is very dirty and fittings are very old.\")\n",
    "\n",
    "print('Review 1:', predict_review1, predictionResult(predict_review1))\n",
    "print('Review 2:', predict_review2, predictionResult(predict_review2))\n",
    "print('Review 3:', predict_review3, predictionResult(predict_review3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: [    1   940     3    34  2957   153  1078   337    18     9   259     5\n",
      "     1  1756     7   153    34   154     9   259     5     9  4686  4687\n",
      "  9832     1   911  4445 11426    36    37     9   206   812   201     9\n",
      "     0     1   183  2624   679     5   281    20     3     1  2334  2070\n",
      "     1  1439   223     3     9     0    76   813   393   153  2114  3793\n",
      "   175   281  5507    33   332     1  2863     5  1712     0   138   107\n",
      "  1885   780   134  1131    76  2009   281   160    41     1   674     5\n",
      "     1  2678   153   107   136   153   107    27   780    76     0    33\n",
      "     0  2849    76 14888    39  2827     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0] y: [ 1.  0.]\n",
      "(1, 120)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.2205226 ,  0.79300803]], dtype=float32)"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_idx= 7785\n",
    "\n",
    "print(\"x:\", test_dataX[test_idx], \"y:\", test_dataY[test_idx])\n",
    "\n",
    "test_data0 = np.reshape(test_dataX[test_idx], (1, 120))\n",
    "print(test_data0.shape)\n",
    "model.predict(test_data0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7787, 120)\n",
      "(7787,)\n",
      "[    8  1122  2978    11     3   300     9   272     7  5189    20    13\n",
      "     5     3    39   284    22   117     4   772  1330    54   469    39\n",
      "   397     1   187    16 17775  1926    12     5    68    22   244     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0]\n"
     ]
    }
   ],
   "source": [
    "print(test_dataX.shape)\n",
    "print(test_dataY.shape)\n",
    "print(test_dataX[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
